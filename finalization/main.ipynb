{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Environment Setup**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve config file, if using colab (nothing should happen if you use Windows)\n",
    "!cp './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/config.py' '.'\n",
    "!mkdir data\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/data/' '.'\n",
    "!mkdir models\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/models/' '.'\n",
    "!mkdir technical\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/technical/' '.'\n",
    "!mkdir utils\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/utils/' '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *                            # config.py\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GCS Integration**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isWindows():\n",
    "  import utils.gcs_windows as gcs \n",
    "elif isColab():\n",
    "  import utils.gcs_colab as gcs\n",
    "else:\n",
    "  raise NotImplementedError('OS is not supported yet')\n",
    "\n",
    "if isColab():\n",
    "  gcs.init()\n",
    "# no need of buckets for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### tf-side debug ###\n",
    "# more info: https://github.com/tensorflow/tensorflow/issues/29931\n",
    "import tensorflow as tf\n",
    "temp = tf.zeros([2, 16, 16, 3])  # Or tf.zeros\n",
    "tf.keras.applications.vgg16.preprocess_input(temp)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.pipeline import *\n",
    "from technical.accelerators import strategy\n",
    "from utils.generator_loading_utils import load_generator_checkpoint\n",
    "from utils.encoder_loading_utils import load_encoder_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "##### Create and load saved generator here (checkpoint) #####\n",
    "# please put generator's saved checkpoint in OUTPUT/generator_checkpoints (GCS for colab)\n",
    "RUN = True\n",
    "if RUN:\n",
    "  generator = load_generator_checkpoint(strategy)\n",
    "  print(generator)\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create and load saved encoder here (checkpoint) #####\n",
    "# please put encoder's saved checkpoint in OUTPUT/encoder_checkpoints (GCS for colab)\n",
    "RUN = True\n",
    "if RUN:\n",
    "  encoder = load_encoder_checkpoint(strategy)\n",
    "  print(encoder)\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = encoder.model.layers[-1].output.shape[1:] \n",
    "IMAGE_SHAPE = encoder.model.layers[0].output.shape[1:] \n",
    "IMAGE_SIZE = [IMAGE_SHAPE[0], IMAGE_SHAPE[0]]\n",
    "print(\"Latent size: \" + str(LATENT_SIZE))\n",
    "print(\"Image shape: \" + str(IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: crop\n",
    "cropped_lips = None\n",
    "plt.imshow(cropped_lips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Encode the cropped lips\n",
    "encoded = encoder.model(np.expand_dims(preprocess(cropped_lips, None)[0], 0))\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Regeneration (w/o injections)\n",
    "regenerated = generator.model(encoded, training=False)[0]\n",
    "plt.imshow(regenerated)\n",
    "print(\"Visual loss: \" + str(float(tf.keras.losses.MSE(tf.keras.backend.flatten(image), tf.keras.backend.flatten(image2)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TODO: Replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experiments**\n",
    "Just a playground for trying out codes, nothing related at all, do not execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597313004689",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}