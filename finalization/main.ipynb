{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Environment Setup**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve config file, if using colab (nothing should happen if you use Windows)\n",
    "!cp './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/config.py' '.'\n",
    "!mkdir data\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/data/' '.'\n",
    "!mkdir models\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/models/' '.'\n",
    "!mkdir technical\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/technical/' '.'\n",
    "!mkdir utils\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/encoder_engineering/utils/' '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *                            # config.py\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GCS Integration**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isWindows():\n",
    "  import utils.gcs_windows as gcs \n",
    "elif isColab():\n",
    "  import utils.gcs_colab as gcs\n",
    "else:\n",
    "  raise NotImplementedError('OS is not supported yet')\n",
    "\n",
    "if isColab():\n",
    "  gcs.init()\n",
    "# no need of buckets for this project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### tf-side debug ###\n",
    "# more info: https://github.com/tensorflow/tensorflow/issues/29931\n",
    "import tensorflow as tf\n",
    "temp = tf.zeros([2, 16, 16, 3])  # Or tf.zeros\n",
    "tf.keras.applications.vgg16.preprocess_input(temp)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from data.pipeline import *\n",
    "from technical.accelerators import strategy\n",
    "from utils.generator_loading_utils import load_generator_checkpoint\n",
    "from utils.encoder_loading_utils import load_encoder_checkpoint\n",
    "from utils.face_utils import detect_and_crop_lips, replace_lips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "##### Create and load saved generator here (checkpoint) #####\n",
    "# please put generator's saved checkpoint in OUTPUT/generator_checkpoints (GCS for colab)\n",
    "RUN = True\n",
    "if RUN:\n",
    "  generator = load_generator_checkpoint(strategy, model_type='256')\n",
    "  print(generator)\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Create and load saved encoder here (checkpoint) #####\n",
    "# please put encoder's saved checkpoint in OUTPUT/encoder_checkpoints (GCS for colab)\n",
    "RUN = True\n",
    "if RUN:\n",
    "  encoder = load_encoder_checkpoint(strategy)\n",
    "  print(encoder)\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = encoder.model.layers[-1].output.shape[1:] \n",
    "IMAGE_SHAPE = encoder.model.layers[0].output.shape[1:] \n",
    "IMAGE_SIZE = [IMAGE_SHAPE[0], IMAGE_SHAPE[0]]\n",
    "print(\"Latent size: \" + str(LATENT_SIZE))\n",
    "print(\"Image shape: \" + str(IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## input\n",
    "img_name = 'test_2.png'\n",
    "img_path = os.path.join(DIR, os.path.join('samples', img_name))\n",
    "img = load_image(img_path)\n",
    "#plt.imshow(img[:, :, [2, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## crop\n",
    "cropped_lips, p_data = detect_and_crop_lips(img_full=img)\n",
    "cropped_lips = np.array(cropped_lips)/255\n",
    "#plt.imshow(cropped_lips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = cropped_lips #cv2.resize(cropped_lips, dsize=(90, 90), interpolation=cv2.INTER_CUBIC)\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Encode the cropped lips\n",
    "encoded = encoder.model(np.expand_dims(resized, 0))\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Regeneration (w/o injections)\n",
    "regenerated = generator.model(encoded, training=False)[0]\n",
    "plt.imshow(regenerated)\n",
    "print(\"Visual loss: \" + str(float(tf.keras.losses.MSE(tf.keras.backend.flatten(resized), tf.keras.backend.flatten(regenerated)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Replacement\n",
    "new_img = replace_lips(regenerated.numpy(), p_data, img_full=cv2.resize(img, dsize=(90, 90), interpolation=cv2.INTER_CUBIC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experiments**\n",
    "Just a playground for trying out codes, nothing related at all, do not execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGBA))\n",
    "plt.imshow(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_x, min_y, max_x, max_y, offset_x, offset_y = p_data\n",
    "cropped_lips_pil = Image.fromarray((cropped_lips*255).astype('uint8'))\n",
    "cropped_lips_pil = cropped_lips_pil.crop((offset_x, offset_y, offset_x+(max_x-min_x), offset_y+(max_y-min_y)))\n",
    "img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGBA))\n",
    "img_pil.paste(cropped_lips_pil, (min_x, min_y), cropped_lips_pil)\n",
    "plt.imshow(img_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_x, min_y, max_x, max_y, offset_x, offset_y = p_data\n",
    "img_tmp = (cropped_lips*255).astype('uint8')\n",
    "cropped_lips_pil = Image.fromarray(img_tmp)\n",
    "cropped_lips_pil = cropped_lips_pil.crop((offset_x, offset_y, offset_x+(max_x-min_x), offset_y+(max_y-min_y)))\n",
    "plt.imshow(cropped_lips_pil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "6eb4991bf65e38b0cae10071082bf7d19677db44169e53c1726170efc336e1b8"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}