{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Environment Setup**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve config file, if using colab (nothing should happen if you use Windows)\n",
    "!cp './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/config.py' '.'\n",
    "!mkdir data\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/data/' '.'\n",
    "!mkdir models\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/models/' '.'\n",
    "!mkdir technical\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/technical/' '.'\n",
    "!mkdir trainers\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/trainers/' '.'\n",
    "!mkdir utils\n",
    "!cp -a './drive/My Drive/Live Workspace/generative-facial-cosmetics/model_engineering/utils/' '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *                            # config.py\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GCS Integration**\n",
    "Run all when initiating session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if isWindows():\n",
    "  import utils.gcs_windows as gcs \n",
    "elif isColab():\n",
    "  import utils.gcs_colab as gcs\n",
    "else:\n",
    "  raise NotImplementedError('OS is not supported yet')\n",
    "\n",
    "gcs.init()\n",
    "\n",
    "#BUCKET1_GS, BUCKET1 = gcs.mount_bucket(\"ffhq-1024-lips-1\")\n",
    "BUCKET1_GS = BUCKET1 = \"C:\\\\Users\\\\comtalyst\\\\Documents\\\\Local_Workspace\\\\testdata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Environment Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from technical.accelerators import strategy\n",
    "from data.pipeline import *\n",
    "from trainers.stylegan import train, load_checkpoint, gen_loss_dict, disc_loss_dict\n",
    "from models.discriminator import Discriminator\n",
    "from models.generator import Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = Generator(strategy, '512')\n",
    "discriminator = Discriminator(strategy, '512')\n",
    "current_progress = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Load saved models here if not the first generation (SavedModel) #####\n",
    "RUN = False\n",
    "# Warning, using this format on colab may cause the \"'NoneType' object has no attribute 'get'\" bug\n",
    "if RUN:\n",
    "  last_epoch = 0\n",
    "  current_progress = 2\n",
    "  generator.load(its_progress=current_progress, strategy=strategy, fname=\"generator\" + \"-p_\" + str(current_progress) + \"-e_\" + str(last_epoch))\n",
    "  discriminator.load(its_progress=current_progress, strategy=strategy, fname=\"discriminator\" + \"-p_\" + str(current_progress) + \"-e_\" + str(last_epoch))\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Load saved models here if not the first generation (checkpoint) #####\n",
    "RUN = True\n",
    "# make sure to add progress to the models until reach intended checkpoint's progress\n",
    "if RUN:\n",
    "  load_checkpoint(generator, discriminator, strategy, True)\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Add progress to models here #####\n",
    "RUN = True\n",
    "if RUN:\n",
    "  generator.progress(strategy)\n",
    "  discriminator.progress(strategy)\n",
    "  current_progress += 1\n",
    "else:\n",
    "  print(\"Running switch for this cell is off, skipping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LATENT_SIZE = Generator.LATENT_SIZE \n",
    "IMAGE_SHAPE = generator.image_shape\n",
    "IMAGE_SIZE = [IMAGE_SHAPE[0], IMAGE_SHAPE[0]]\n",
    "print(\"Latent size: \" + str(LATENT_SIZE))\n",
    "print(\"Image shape: \" + str(IMAGE_SHAPE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##### Prepare dataset #####\n",
    "# some bug\n",
    "import tensorflow as tf\n",
    "tf.Tensor.ndim = tf.rank\n",
    "training_dataset = get_dataset(BUCKET1_GS, True, True, True, BUCKET1, image_size=IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Pre-Train Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1,LATENT_SIZE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## full model\n",
    "image = generator.model(noise, training=False)\n",
    "plt.imshow(image[0])\n",
    "print(discriminator.model(image, training=False).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## fading model \n",
    "# alpha 0 should be the same as full output from prev generation\n",
    "# alpha 1 should be the same as full output from current generation\n",
    "generator.setAlpha(1)\n",
    "image = generator.model_fade(noise, training=False)\n",
    "plt.imshow(image[0])\n",
    "print(discriminator.model_fade(image, training=False).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FADE_EPOCHS = 0\n",
    "EPOCHS = 600\n",
    "\n",
    "if isColab():                   # some colab's tpu side bug\n",
    "  import numpy as np\n",
    "  np.rank = np.ndim\n",
    "train(generator, discriminator, training_dataset, FADE_EPOCHS, EPOCHS, BATCH_SIZE, strategy, lr=[5e-5, 5e-5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Saving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator.save(0, strategy)\n",
    "discriminator.save(0, strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise = tf.random.normal([1,LATENT_SIZE])\n",
    "image = generator.model(noise, training=False)\n",
    "plt.imshow(image[0])\n",
    "print(discriminator.model(image, training=False).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Experiments**\n",
    "Just a playground for trying out codes, nothing related at all, do not execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### just code testing\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt \n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "\n",
    "fbytes = tf.io.read_file('samples\\\\musk_lips_cropped.png')\n",
    "image = tf.image.decode_png(fbytes, channels=4)\n",
    "max_resize = 0.5\n",
    "random_scale = max_resize + np.random.rand()*(1 - max_resize)\n",
    "image = tf.image.central_crop(image, random_scale)\n",
    "image = Image.fromarray(image.numpy())\n",
    "image = image.resize((206, 206))\n",
    "image = tf.convert_to_tensor(np.array(image))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tf.keras.preprocessing.image.random_rotation(image.numpy(), 40, row_axis=0, col_axis=1, channel_axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tf.keras.preprocessing.image.random_rotation(image.numpy(), 40, row_axis=0, col_axis=1, channel_axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1597855327588",
   "display_name": "Python 3.7.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}